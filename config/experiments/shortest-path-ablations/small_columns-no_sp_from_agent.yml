batch_size: 32
checkpoint_dir: null
checkpoint_freq: 1000
checkpoint_path: null
checkpoints_dir: checkpoints
collision_penalty: 0.25
discount_factor: 0.99
distance_to_receptacle_channel_scale: 0.25
experiment_name: small_columns-no_sp_from_agent
exploration_timesteps: 6000
final_exploration: 0.01
fixed_step_size: null
grad_norm_clipping: 10
inactivity_cutoff: 100
learning_rate: 0.01
learning_starts: 1000
log_dir: null
logs_dir: logs
ministep_size: 0.25
model_path: null
nonmovement_penalty: 0.25
num_cubes: 10
num_input_channels: 3
obstacle_config: small_columns
partial_rewards_scale: 2.0
policy_type: dense_action_space
position_channel_scale: 0.25
random_seed: null
replay_buffer_size: 10000
room_length: 1.0
room_width: 0.5
run_name: null
shortest_path_channel_scale: 0.25
steering_commands_num_turns: 4
target_update_freq: 1000
total_timesteps: 60000
use_distance_to_receptacle_channel: false
use_double_dqn: true
use_position_channel: false
use_shortest_path_channel: false
use_shortest_path_movement: true
use_shortest_path_partial_rewards: true
use_shortest_path_to_receptacle_channel: true
use_steering_commands: false
weight_decay: 0.0001
